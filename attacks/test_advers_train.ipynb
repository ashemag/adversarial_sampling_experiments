{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to **add the root directory** to system path so that you can import all the necessary modules in this notebook correctly. **Important**: The **root directory is the directory two levels up from the current working directory**, and **one level up from the \"adversarial_sampling_experiments\" directory**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory:  C:\\mlp_new\\adversarial_sampling_experiments\\attacks\n",
      "two directories up:  C:\\mlp_new\n",
      "added root dir to sys.path:  C:\\mlp_new\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "two_up_dir = str(Path(os.getcwd()).parents[1]) # you have to cast to string otherwise it won't work.\n",
    "print(\"current directory: \",os.getcwd())\n",
    "print(\"two directories up: \",two_up_dir)\n",
    "\n",
    "if two_up_dir not in sys.path:\n",
    "    sys.path.append(two_up_dir)\n",
    "    print(\"added root dir to sys.path: \",two_up_dir)\n",
    "else:\n",
    "    print(\"root dir: \",two_up_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary\n",
    "- Adversarially attacking a batch of images and showing the results.\n",
    "    - Fetching a batch of images.\n",
    "- Prepare data for adversarial training.\n",
    "    - Loading in a pre-trained model.\n",
    "    - Saving the augmented dataset.\n",
    "- Adversarially training a network.\n",
    "\n",
    "The tests that we will perform will be using the MNIST dataset, and a simple feed forward neural network (FNN); but can easily be extended to more complicated datasets and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarially attacking a batch of images and showing the results\n",
    "The hyperparameters of the attacks that we use are the same as the ones used to produce figure 3 in this paper: https://arxiv.org/pdf/1805.12152.pdf.\n",
    "\n",
    "The above paper experiments with two types of attacks: **max-nrom PGD**, and **square-norm PGD**. The attacks are based on Madry's paper: https://arxiv.org/pdf/1706.06083.pdf\n",
    "\n",
    "In appendix A.4 the author of the paper specify the $\\epsilon$ used. For the MNIST dataset\n",
    "- max-norm attack epsilon is 0.3,\n",
    "- square-norm attack epsilon is 4.\n",
    "\n",
    "Other hyper-parameters:\n",
    "- **Intialization of PGD**. In appendix A.3 authors say they start PGD \"from a random initial pertubation\".\n",
    "    - From the Madry's paper:  \"Each run starts at a uniformly random point in the inf-ball around the same natural example\"\n",
    "- **Number of iterations to run PGD for**. From Madry's paper section 5 table 1:\n",
    "    - \"We run 40 iterations of projected gradient descent as our adversary, with a step size of 0.01 (we choose to take gradient steps in the ∞ norm, i.e. adding the sign of the gradient, since this makes the choice of the step size simpler). We train and evaluate against perturbations of size ε = 0.3\"\n",
    "\n",
    "Note: It may be interesting to do experiments with both small adversarial pertubations and high pertubations. Maybe high is better for correcting data imbalances?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CPU\n",
      "building cnn module\n",
      "torch.Size([2, 1, 28, 28]) input\n",
      "torch.Size([2, 100]) -fc-relu\n",
      "torch.Size([2, 10]) -fc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 16/16 [00:00<00:00, 49.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.2825    0.3       0.06885  ... -0.003471  0.3      -0.3     ]\n",
      "   [-0.3       0.3      -0.3      ...  0.3       0.3      -0.04456 ]\n",
      "   [ 0.2164    0.3       0.3      ... -0.03482   0.3      -0.1637  ]\n",
      "   ...\n",
      "   [ 0.3       0.275    -0.3      ...  0.1697   -0.3      -0.3     ]\n",
      "   [-0.3       0.3      -0.3      ... -0.3       0.29      0.2734  ]\n",
      "   [ 0.3      -0.3       0.2976   ...  0.3      -0.281    -0.3     ]]]\n",
      "\n",
      "\n",
      " [[[ 0.084    -0.3       0.3      ...  0.1438    0.3       0.3     ]\n",
      "   [-0.131    -0.29      0.3      ... -0.2052    0.3       0.1888  ]\n",
      "   [-0.1368    0.3      -0.3      ... -0.1952    0.1222    0.1552  ]\n",
      "   ...\n",
      "   [-0.1897    0.018     0.1837   ...  0.3       0.221     0.3     ]\n",
      "   [ 0.1952    0.1442    0.03096  ...  0.3      -0.3      -0.3     ]\n",
      "   [ 0.1229   -0.10004  -0.3      ... -0.3      -0.3      -0.3     ]]]\n",
      "\n",
      "\n",
      " [[[-0.3      -0.2101    0.3      ...  0.3      -0.3       0.3     ]\n",
      "   [ 0.3      -0.3       0.1666   ... -0.3       0.158     0.3     ]\n",
      "   [ 0.3       0.26     -0.3      ... -0.12067   0.3       0.3     ]\n",
      "   ...\n",
      "   [-0.3      -0.10223   0.3      ...  0.1219   -0.1747    0.3     ]\n",
      "   [ 0.26     -0.3      -0.1643   ...  0.2705   -0.1787   -0.3     ]\n",
      "   [ 0.18      0.29     -0.2935   ... -0.2825    0.3       0.13    ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.3      -0.3       0.2      ...  0.00704  -0.3       0.3     ]\n",
      "   [ 0.3      -0.1791    0.3      ... -0.272     0.2051    0.3     ]\n",
      "   [ 0.3       0.3      -0.3      ... -0.3       0.3       0.3     ]\n",
      "   ...\n",
      "   [-0.3       0.03004   0.3      ...  0.3      -0.2366   -0.3     ]\n",
      "   [-0.2344   -0.3       0.3      ...  0.1394   -0.3      -0.3     ]\n",
      "   [-0.1866   -0.3      -0.1227   ... -0.0986    0.12366   0.1586  ]]]\n",
      "\n",
      "\n",
      " [[[ 0.06805   0.3      -0.3      ... -0.3      -0.3      -0.292   ]\n",
      "   [-0.2812   -0.1422   -0.12366  ...  0.3      -0.27      0.3     ]\n",
      "   [ 0.3       0.1887    0.3      ... -0.3       0.04346  -0.02786 ]\n",
      "   ...\n",
      "   [-0.02719  -0.11615   0.01324  ...  0.3       0.3       0.3     ]\n",
      "   [ 0.3      -0.3      -0.1768   ...  0.07007  -0.3       0.3     ]\n",
      "   [-0.02983   0.2301   -0.3      ...  0.3       0.3       0.3     ]]]\n",
      "\n",
      "\n",
      " [[[ 0.1128   -0.3       0.3      ...  0.1       0.3      -0.04456 ]\n",
      "   [-0.3       0.3       0.3      ... -0.3       0.3       0.2517  ]\n",
      "   [-0.3      -0.3       0.11005  ... -0.3      -0.3      -0.3     ]\n",
      "   ...\n",
      "   [-0.04126   0.3      -0.2854   ... -0.00995  -0.3       0.11383 ]\n",
      "   [-0.2837   -0.3       0.3      ...  0.29     -0.0819   -0.3     ]\n",
      "   [-0.10406  -0.3       0.2338   ... -0.3       0.3      -0.2229  ]]]]\n"
     ]
    }
   ],
   "source": [
    "# importing necessary modules. note: make sure to add the root directory to sys.path (see start of notebook)\n",
    "\n",
    "from adversarial_sampling_experiments.data_providers import ImageDataGetter\n",
    "from adversarial_sampling_experiments.data_providers import DataProvider\n",
    "from adversarial_sampling_experiments.models.simple_fnn import *\n",
    "from adversarial_sampling_experiments.attacks.advers_attacks import *\n",
    "from adversarial_sampling_experiments.attacks.data_augmenter import *\n",
    "\n",
    "'''\n",
    "remarks:\n",
    "(1) x is an array. shape: (batch_size, num_channels, height, width).\n",
    "    y is an array. shape: (batch_size,). corresponds to integer encodings of labels.\n",
    "(2) ImageDataGetter get's us the complete dataset. For demonstration purposes we only want a small sub-sample (e.g. 16 images).\n",
    "    We can use DataProvider to fetch a random batch of images.\n",
    "    Note:\n",
    "        make_one_hot = False means that iterator returns integer encoded y i.e. y maintains shape (batch_size,).\n",
    "        rng = None means the default seed is used when shuffling the data and fetching a random batch.\n",
    "(3) performing an advers attack requires loading in a *trained* model.\n",
    "'''\n",
    "\n",
    "x, y = ImageDataGetter.mnist(filename=os.path.join(globals.ROOT_DIR, 'data/mnist-train.npz')) # (1)\n",
    "data_iterator = DataProvider(x,y,batch_size=16,max_num_batches=1,make_one_hot=False,rng=None) # (2)\n",
    "x, y = data_iterator.__next__()\n",
    "\n",
    "\n",
    "model = FeedForwardNetwork(img_shape=(1, 28, 28), num_classes=10)\n",
    "model.load_model(\n",
    "    model_path=os.path.join(globals.ROOT_DIR,'saved_models/simple_fnn/model_epoch_49') # (3)\n",
    ")\n",
    "\n",
    "attack = LInfProjectedGradientAttack(\n",
    "    model = model,\n",
    "    steps = 40,\n",
    "    alpha = 0.01, # step size\n",
    "    epsilon = 0.3,\n",
    "    rand = True, # initialize at uniformly random feasible point\n",
    "    targeted=False\n",
    ")\n",
    "\n",
    "x_adv = DataAugmenter.advers_attack(x,y,attack=attack)\n",
    "\n",
    "from adversarial_sampling_experiments.analysis.data_viewer import ImageDataViewer\n",
    "\n",
    "plot_dict = {}\n",
    "axs = plt.subplots(4,4).reshape(-1,)\n",
    "labels = []\n",
    "for i in range(len(axs)):\n",
    "    plot_dict[labels[i]] = {'ax': axs[i],'img': x_adv[i]}\n",
    "\n",
    "ImageDataViewer.grid(plot_dict)\n",
    "\n",
    "\n",
    "# show original\n",
    "# show augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}